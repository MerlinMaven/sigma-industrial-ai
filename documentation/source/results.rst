===========================
Results and Performance Analysis
===========================

This section presents the performance of our final, optimized pipeline. To provide a clear and detailed analysis, we will first focus on a specific case study: the **Vertical Linear Rail**.

The methodology described previously was applied systematically to each major component of the industrial cell (all three robots, conveyors, etc.). While each component yielded its own optimized model, the overall conclusions remained consistent. The case of the linear rail serves as a representative example of the system's performance.

Case Study: Anomaly Detection on the Vertical Linear Rail
-----------------------------------------------------------

.. note::
   This analysis uses the final pipeline: the **LSTM-based Signature Extractor** followed by the **Optuna-optimized CNN-BiLSTM Processor Model**.

**Qualitative Analysis: Reconstruction & Prediction**

The primary evaluation of our model involves a visual inspection of its ability to reconstruct the system's behavior. The following plots compare the original time-series signal with the outputs of our two pipelines: the reconstruction of the current state and the prediction of the state one step into the future.

*(Ins√©rez ici votre graphique principal de comparaison avec le zoom, comme nous l'avons con√ßu pr√©c√©demment)*

As observed, the model demonstrates high fidelity in both tasks. The reconstructed signal (in red) closely follows the original signal, indicating a very low reconstruction error for normal data. The predicted signal (in blue), while slightly less precise, successfully captures the dynamic trends of the system, proving the model's understanding of its behavior.

**Quantitative Analysis: Performance Metrics**

To quantify this performance, we calculated the Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE) for both tasks on the test dataset.

*(Ins√©rez ici votre rapport textuel format√© pour le Rail Lin√©aire)*
::
    ================================================================================
    üìä RAPPORT DE PERFORMANCE QUANTITATIF (sur donn√©es d√©normalis√©es)
    ================================================================================
    Feature              | T√¢che              | MAE             | RMSE        
    --------------------------------------------------------------------------
    rail_position        | Reconstruction     | 10.0771         | 15.5968     
                         | Pr√©diction (t+1)   | 13.7775         | 25.2882     
    --------------------------------------------------------------------------
    rail_speed           | Reconstruction     | 73.3913         | 132.0795    
                         | Pr√©diction (t+1)   | 87.5624         | 164.0219    
    --------------------------------------------------------------------------
    rail_acceleration    | Reconstruction     | 745.5022        | 1271.2927   
                         | Pr√©diction (t+1)   | 814.0240        | 1365.6223   
                     
**Benchmarking against Classical Methods**

Finally, to validate our approach, we compared the anomaly scores generated by our deep learning model against those from Isolation Forest and One-Class SVM.

*(Ins√©rez ici le Violin Plot de comparaison, comme nous l'avons con√ßu pr√©c√©demment)*

The score distribution clearly shows that our **CNN-BiLSTM AE** provides the sharpest and most reliable separation between normal and anomalous behavior, confirming the superiority of our signature-based, deep learning approach.

Summary of Models for the Entire Industrial Cell
--------------------------------------------------

Following the same rigorous methodology of experimentation and optimization for each component of the robotic cell, we have derived a specialized model for each one. The table below summarizes the final selected architectures.

.. list-table::
   :widths: 30 35 35
   :header-rows: 1

   * - Industrial Component
     - Selected Signature Extractor
     - Selected Processor Model
   * - **Robot 1 (Depalletizer)**
     - LSTM AE (Bottleneck: 8)
     - CNN-BiLSTM AE (Optimized)
   * - **Robot 2 (Filler)**
     - LSTM AE (Bottleneck: 8)
     - CNN-BiLSTM AE (Optimized)
   * - **Robot 3 (Palletizer Rail)**
     - LSTM AE (Bottleneck: 8)
     - CNN-BiLSTM AE (Optimized)
   * - **Conveyor_Box**
     - CAE (Bottleneck: 16)
     - Dense AE (Optimized)
   * - **Conveyor_Bottle**
     - CAE (Bottleneck: 16)
     - Dense AE (Optimized)

This modular, custom-tailored approach ensures maximum performance for each component while leveraging a consistent, robust, and scalable end-to-end pipeline.

===========================
Results and Performance Analysis
===========================

This section presents a comprehensive evaluation of our proposed signature-based anomaly detection pipeline. The analysis is designed to answer two key questions:

1.  How effectively does our final model perform its dual tasks of reconstruction and prediction?
2.  How significant is the performance uplift gained by using learned signatures compared to classical methods on raw data?

To answer these, we first present a detailed case study on our primary component, the **Vertical Linear Rail**, followed by a summary benchmark.

Case Study: Anomaly Detection on the Vertical Linear Rail
-----------------------------------------------------------
... (Ici, vous mettez vos graphiques et m√©triques pour votre meilleur mod√®le, comme nous l'avons discut√© pr√©c√©demment)...

Benchmarking: The Value of a Signature-Based Approach
-------------------------------------------------------

To validate our core hypothesis, we benchmarked our final model against two industry-standard baselines: **Isolation Forest** and **One-Class SVM**. Crucially, we ran these baselines under two conditions:
1.  On the **raw, high-dimensional data** (flattened sequences).
2.  On the **learned, low-dimensional signatures** generated by our LSTM encoder.

.. figure:: /_static/violin_plot_comparison.png
   :align: center
   :width: 800px
   :alt: Comparison of Anomaly Score Distributions

The score distributions above provide clear evidence. Models operating on raw data exhibit wide, uncertain distributions, struggling to separate normal from anomalous states. In contrast, **all models, including the classical ones, show a dramatic improvement in discrimination when operating on the learned signatures.**

The following table quantifies this performance uplift based on the 95th percentile of the anomaly scores, a key indicator of a model's sensitivity.

.. list-table::
   :widths: 25 25 25 25
   :header-rows: 1

   * - Model
     - Score on Raw Data (Q95)
     - Score on Signatures (Q95)
     - Performance Uplift
   * - **Isolation Forest**
     - 0.8064
     - 0.8678
     - **+7.6%**
   * - **One-Class SVM**
     - 0.8650
     - 0.9481
     - **+9.6%**
   * - **CNN-BiLSTM-AE (Ours)**
     - N/A
     - **0.9985 (Best)**
     - N/A


**Conclusion of Analysis**

The results are unequivocal. The signature-based approach provides a superior feature space that enhances the performance of all detection methods. Our proposed `CNN-BiLSTM-AE` model, which is specifically designed to leverage this space, achieves the highest level of performance, demonstrating its state-of-the-art capabilities for this task.

... (Suivi par votre tableau r√©capitulatif des mod√®les par composant) ...
